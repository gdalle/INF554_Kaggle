{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from harmonic_mean import *\n",
    "from sklearn import linear_model, ensemble, tree\n",
    "from evaluation import *\n",
    "from data_processing import *\n",
    "from sklearn import preprocessing, model_selection,pipeline,metrics,externals\n",
    "from sklearn_pandas.pipeline import TransformerPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Loading data ...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read csv files\n",
    "\n",
    "print(\"=================\")\n",
    "print(\"Loading data ...\")\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"data/test.csv\", index_col=0)\n",
    "\n",
    "print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Processing data ...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=================\")\n",
    "print(\"Processing data ...\")\n",
    "\n",
    "# Turn DataFrames into arrays for scikit-learn\n",
    "# Forget the target column in X\n",
    "# train_features = [\n",
    "#     \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "# \t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "# \t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "# \t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "# \t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "# \t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "# \t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "# \t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "# \t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "# \t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "# \t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "# \t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "# \t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "# \t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "# \t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "# \t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "# \t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "# \t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "# \t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "# \t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "# \t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "# \t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "# \t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "# \t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "# \t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "# \t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "# \t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "# \t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "# \t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "# \t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "# \t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "# \t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "# \t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "# \t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "#     \"target\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# train = train[train_features]\n",
    "train = train.drop(train.columns[train.columns.str.contains(\"calc\")], axis=1)\n",
    "train_0 = train.drop(\"target\", axis=1)\n",
    "\n",
    "name_to_index = {name: train_0.columns.get_loc(name) for name in train_0.columns}\n",
    "\n",
    "X0 = np.array(train_0)\n",
    "y0 = np.array(train[\"target\"])\n",
    "\n",
    "X_test = np.array(test)\n",
    "\n",
    "print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Setting the pipeline ...\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=================\")\n",
    "print(\"Setting the pipeline ...\")\n",
    "\n",
    "# Define the num pipeline\n",
    "num_selector = filter_num_transform(name_to_index)\n",
    "num_imputer = preprocessing.Imputer(missing_values=-1, strategy=\"mean\")\n",
    "num_pipeline = pipeline.Pipeline([\n",
    "    (\"selector\", num_selector),\n",
    "    (\"imputer\", num_imputer),\n",
    "    (\"scaler\", preprocessing.StandardScaler())\n",
    "])\n",
    "\n",
    "# Define the bin pipeline\n",
    "bin_selector = filter_bin_transform(name_to_index)\n",
    "bin_imputer = preprocessing.Imputer(missing_values=-1, strategy=\"most_frequent\")\n",
    "bin_pipeline = pipeline.Pipeline([\n",
    "    (\"selector\", bin_selector),\n",
    "    (\"imputer\", bin_imputer)\n",
    "])\n",
    "\n",
    "# Define the cat pipeline\n",
    "cat_selector = filter_cat_transform(name_to_index)\n",
    "cat_imputer = preprocessing.Imputer(missing_values=-1, strategy=\"most_frequent\")\n",
    "cat_pipeline = pipeline.Pipeline([\n",
    "    (\"selector\", cat_selector),\n",
    "    (\"imputer\", cat_imputer),\n",
    "    (\"binarizer\", preprocessing.OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = pipeline.FeatureUnion([(\"num\", num_pipeline), (\"bin\", bin_pipeline), (\"cat\", cat_pipeline)])\n",
    "\n",
    "base = ensemble.GradientBoostingClassifier(verbose=2)\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"clf\",base)\n",
    "])\n",
    "\n",
    "cv = model_selection.StratifiedKFold(n_splits=4)\n",
    "scorer = metrics.make_scorer(gini_scorer,needs_proba=True)\n",
    "print(\"Done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=nan, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "[CV] ...................... , score=-0.2837175813349814, total=23.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed: 23.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... , score=-0.27037248733437785, total=23.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed: 23.3min remaining: 23.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=-0.2791996513997706, total=23.4min\n",
      "[CV] ....................... , score=-0.286552356281614, total=23.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed: 23.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed: 23.5min finished\n"
     ]
    }
   ],
   "source": [
    "clf1 = xgboost.XGBClassifier(\n",
    "    scale_pos_weight=1.6,\n",
    "    max_depth=3,\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.07,\n",
    ")\n",
    "\n",
    "clf2 = xgboost.XGBClassifier(\n",
    "    scale_pos_weight=1.6,\n",
    "    max_depth=4,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.07,\n",
    ")\n",
    "\n",
    "clf3 = xgboost.XGBClassifier(\n",
    "    scale_pos_weight=1.6,\n",
    "    max_depth=4,\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.07,\n",
    ")\n",
    "\n",
    "harmonic_clf = HarmonicMeanClassifier(list_classifiers=[clf1, clf2, clf3])\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"clf\", harmonic_clf)\n",
    "])\n",
    "cross_val = model_selection.cross_val_score(pipe, X0, y0, cv=cv, scoring=scorer, verbose=10, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=400, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1.6, seed=0, silent=True, subsample=1)\n",
      "-0.345115247134\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X0, y0)\n",
    "print(gini_normalized(y0, pipe.predict_proba(X0)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HarmonicMeanClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0cf07060f967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mharmonic_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'HarmonicMeanClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "harmonic_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Predicting for submission ...\n"
     ]
    }
   ],
   "source": [
    "print(\"=================\")\n",
    "print(\"Predicting for submission ...\")\n",
    "y_test_p = pipe.predict_proba(X_test)[:,1]\n",
    "prediction = pd.DataFrame(\n",
    "    index=test.index,\n",
    "    data=np.round(y_test_p, 3),\n",
    "    columns=[\"target\"])\n",
    "prediction.to_csv(\"data/submission.csv\")\n",
    "print(\"Done\\n\")\n",
    "\n",
    "# externals.joblib.dump(harmonic_clf,\"XGB.pkl\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
